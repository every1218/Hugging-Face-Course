# LLM을 이용한 텍스트 생성 추론 심층 분석 (Deep dive into Text Generation Inference with LLMs)[[inference-with-llms]]

지금까지는 텍스트 분류나 요약과 같은 다양한 개별 작업과 관련된 트랜스포머 아키텍처를 탐구했습니다. 그러나 대규모 언어 모델(LLM)은 텍스트 생성에 가장 많이 사용되며, 이것이 이 장에서 다룰 내용입니다.

이 페이지에서는 LLM 추론 이면에 있는 핵심 개념을 탐구하여, 이 모델들이 어떻게 텍스트를 생성하는지, 그리고 추론 과정에 관련된 주요 구성 요소에 대한 포괄적인 이해를 제공할 것입니다.

## 기본 사항 이해 (Understanding the Basics)

기본부터 시작하겠습니다. **추론(Inference)**은 훈련된 LLM을 사용하여 주어진 입력 프롬프트로부터 인간과 유사한 텍스트를 생성하는 과정입니다. 언어 모델은 훈련을 통해 얻은 지식을 활용하여 한 번에 한 단어씩 응답을 공식화합니다. 모델은 수십억 개의 매개변수로부터 학습된 **확률**을 활용하여 시퀀스에서 다음 토큰을 예측하고 생성합니다. 이러한 순차적인 생성이 LLM이 일관성 있고 문맥적으로 관련 있는 텍스트를 생성할 수 있게 해주는 요소입니다.

## 어텐션의 역할 (The Role of Attention)

**어텐션 메커니즘**은 LLM이 문맥을 이해하고 일관성 있는 응답을 생성하는 능력을 부여하는 핵심입니다. 다음 단어를 예측할 때, 문장의 모든 단어가 동일한 가중치를 가지는 것은 아닙니다. 예를 들어, *"The capital of France is ..."*라는 문장에서 "France"와 "capital"이라는 단어는 다음에 "Paris"가 와야 함을 결정하는 데 결정적인 역할을 합니다. 관련 정보에 집중하는 이러한 능력을 **어텐션(attention)**이라고 부릅니다.

<img src="https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/unit1/AttentionSceneFinal.gif" alt="Visual Gif of Attention" width="60%">

다음 토큰을 예측하기 위해 가장 관련성 높은 단어를 식별하는 이 프로세스는 매우 효과적인 것으로 입증되었습니다. LLM 훈련의 기본 원칙, 즉 다음 토큰을 예측하는 것은 BERT와 GPT-2 이후로 일반적으로 일관되게 유지되었지만, 신경망의 확장과 어텐션 메커니즘이 점점 더 길어지는 시퀀스에서 더 낮은 비용으로 작동하도록 만드는 데 상당한 발전이 있었습니다.

> [!TIP]
> 요컨대, **어텐션 메커니즘**은 LLM이 일관성 있고 문맥을 인지하는 텍스트를 생성할 수 있는 핵심입니다. 이는 최신 LLM을 이전 세대의 언어 모델과 구별 짓는 요소입니다.

### 문맥 길이와 어텐션 범위 (Context Length and Attention Span)

이제 어텐션을 이해했으므로, LLM이 실제로 처리할 수 있는 문맥의 양을 탐구해 보겠습니다. 이것이 모델의 '**작업 기억(attention span)**' 또는 **문맥 길이(context length)**로 이어집니다.

**문맥 길이**는 LLM이 한 번에 처리할 수 있는 최대 토큰(단어 또는 단어의 일부) 수를 나타냅니다. 이를 모델의 작업 기억 크기라고 생각할 수 있습니다.

이러한 능력은 몇 가지 실제적인 요인에 의해 제한됩니다:
- 모델의 아키텍처 및 크기
- 사용 가능한 컴퓨팅 자원
- 입력 및 원하는 출력의 복잡성

이상적인 세계에서는 모델에 무제한의 문맥을 제공할 수 있겠지만, 하드웨어 제약과 계산 비용으로 인해 이는 비실용적입니다. 이것이 다양한 모델이 능력과 효율성의 균형을 맞추기 위해 서로 다른 문맥 길이로 설계되는 이유입니다.

> [!TIP]
> **문맥 길이**는 모델이 응답을 생성할 때 한 번에 고려할 수 있는 최대 토큰 수입니다.

### 프롬프트 엔지니어링의 기술 (The Art of Prompting)

LLM에 정보를 전달할 때, 우리는 원하는 출력 방향으로 생성을 유도하는 방식으로 입력을 구성합니다. 이것을 **프롬프트 엔지니어링**이라고 합니다.

LLM이 정보를 처리하는 방식을 이해하는 것은 더 나은 프롬프트를 작성하는 데 도움이 됩니다. 모델의 주요 임무는 각 입력 토큰의 중요성을 분석하여 다음 토큰을 예측하는 것이므로, 입력 시퀀스의 워딩이 중요해집니다.

> [!TIP]
> 프롬프트의 신중한 설계는 **원하는 출력 방향으로 LLM의 생성을 유도하는 것**을 더 쉽게 만듭니다.

## 2단계 추론 프로세스 (The Two-Phase Inference Process)

이제 기본 구성 요소를 이해했으므로, LLM이 실제로 텍스트를 생성하는 방식을 자세히 살펴보겠습니다. 이 프로세스는 **프리필(prefill)**과 **디코드(decode)**라는 두 가지 주요 단계로 나눌 수 있습니다. 이 단계들은 조립 라인처럼 함께 작동하며, 각각 일관성 있는 텍스트를 생성하는 데 중요한 역할을 합니다.

### 프리필 단계 (The Prefill Phase)

**프리필 단계**는 요리 준비 단계와 같습니다. 모든 초기 재료가 처리되고 준비되는 곳입니다. 이 단계에는 세 가지 주요 과정이 포함됩니다:

1. **토큰화 (Tokenization)**: 입력 텍스트를 토큰(모델이 이해하는 기본 구성 요소라고 생각하십시오)으로 변환합니다.
2. **임베딩 변환 (Embedding Conversion)**: 이 토큰들을 의미를 포착하는 수치적 표현으로 변환합니다.
3. **초기 처리 (Initial Processing)**: 이 임베딩을 모델의 신경망을 통해 실행하여 문맥에 대한 풍부한 이해를 생성합니다.

이 단계는 모든 입력 토큰을 한 번에 처리해야 하므로 계산 집약적입니다. 응답 작성을 시작하기 전에 전체 단락을 읽고 이해하는 것으로 생각하십시오.

아래 대화형 놀이터에서 다양한 토크나이저를 실험해 볼 수 있습니다:

<iframe
	src="https://agents-course-the-tokenizer-playground.static.hf.space"
	frameborder="0"
	width="850"
	height="450"
></iframe>

### 디코드 단계 (The Decode Phase)

프리필 단계가 입력을 처리한 후, 우리는 **디코드 단계**로 넘어갑니다. 여기서 실제 텍스트 생성이 발생합니다. 모델은 **자동 회귀 프로세스(autoregressive process)** (각 새 토큰이 모든 이전 토큰에 의존하는 방식)를 통해 한 번에 하나의 토큰을 생성합니다.

디코드 단계는 각 새 토큰에 대해 발생하는 몇 가지 주요 단계를 포함합니다:
1. **어텐션 계산 (Attention Computation)**: 문맥을 이해하기 위해 모든 이전 토큰을 되돌아봅니다.
2. **확률 계산 (Probability Calculation)**: 가능한 각 다음 토큰의 가능성을 결정합니다.
3. **토큰 선택 (Token Selection)**: 이러한 확률을 기반으로 다음 토큰을 선택합니다.
4. **계속 여부 확인 (Continuation Check)**: 생성을 계속할지 또는 중지할지를 결정합니다.

이 단계는 모델이 이전에 생성된 모든 토큰과 그 관계를 추적해야 하므로 **메모리 집약적**입니다.

## 샘플링 전략 (Sampling Strategies)

이제 모델이 텍스트를 생성하는 방식을 이해했으므로, 이 생성 프로세스를 제어할 수 있는 다양한 방법을 탐구해 보겠습니다. 작가가 더 창의적이거나 더 정확한 것 중에서 선택할 수 있듯이, 모델이 토큰 선택을 하는 방식을 조정할 수 있습니다.

이 Space에서 **SmolLM2**를 사용하여 기본 디코딩 프로세스를 직접 상호 작용하며 탐색할 수 있습니다 (이 모델의 경우 **EOS** 토큰인 **<|im_end|>**에 도달할 때까지 디코딩합니다):

<iframe
	src="https://agents-course-decoding-visualizer.hf.space"
	frameborder="0"
	width="850"
	height="450"
></iframe>

### 토큰 선택 이해: 확률에서 토큰 선택으로 (Understanding Token Selection: From Probabilities to Token Choices)

모델이 다음 토큰을 선택해야 할 때, 모델은 어휘의 모든 단어에 대한 원시 확률(**로짓(logits)**이라고 함)로 시작합니다. 하지만 이 확률을 실제 선택으로 어떻게 바꿀까요? 그 과정을 분석해 봅시다:

![image](https://huggingface.co/reasoning-course/images/resolve/main/inference/1.png)  

1. **원시 로짓 (Raw Logits)**: 가능한 각 다음 단어에 대한 모델의 초기 직감이라고 생각하십시오.
2. **온도 제어 (Temperature Control)**: 창의성 다이얼과 같습니다. 설정이 높을수록 (>1.0) 선택이 더 무작위적이고 창의적이 되며, 설정이 낮을수록 (<1.0) 더 집중적이고 결정론적이 됩니다.
3. **Top-p (핵심) 샘플링 (Top-p (Nucleus) Sampling)**: 가능한 모든 단어를 고려하는 대신, 우리가 선택한 확률 임계값(예: 상위 90%)에 합산되는 가장 가능성 있는 단어만 살펴봅니다.
4. **Top-k 필터링 (Top-k Filtering)**: k개의 가장 가능성 있는 다음 단어만 고려하는 대체 접근 방식입니다.

### 반복 관리: 출력의 신선함 유지 (Managing Repetition: Keeping Output Fresh)

LLM의 일반적인 문제 중 하나는 자기 반복 경향입니다. 같은 요점으로 계속 돌아가는 화자와 매우 유사합니다. 이를 해결하기 위해 두 가지 유형의 **패널티(penalties)**를 사용합니다:

1. **존재 패널티 (Presence Penalty)**: 이전에 나타난 토큰에 대해 사용 빈도와 관계없이 적용되는 고정 패널티입니다. 이는 모델이 같은 단어를 재사용하는 것을 방지하는 데 도움이 됩니다.
2. **빈도 패널티 (Frequency Penalty)**: 토큰이 사용된 횟수에 따라 증가하는 **스케일링 패널티**입니다. 단어가 더 많이 나타날수록 다시 선택될 가능성이 줄어듭니다.

![image](https://huggingface.co/reasoning-course/images/resolve/main/inference/2.png)  

이러한 패널티는 다른 샘플링 전략이 적용되기 전에 토큰 선택 프로세스의 초기에 적용되어 원시 확률을 조정합니다. 이들을 모델이 새로운 어휘를 탐색하도록 장려하는 부드러운 유도 장치라고 생각하십시오.

### 생성 길이 제어: 경계 설정 (Controlling Generation Length: Setting Boundaries)

좋은 이야기에 적절한 속도와 길이가 필요하듯이, LLM이 생성하는 텍스트의 양을 제어하는 방법이 필요합니다. 이는 실제 응용 분야에서 매우 중요합니다. 응답이 트윗 길이이든 전체 블로그 게시물이든 상관없이 말입니다.

다음과 같은 여러 가지 방법으로 생성 길이를 제어할 수 있습니다:
1. **토큰 제한 (Token Limits)**: 최소 및 최대 토큰 수를 설정합니다.
2. **중지 시퀀스 (Stop Sequences)**: 생성의 끝을 알리는 특정 패턴을 정의합니다.
3. **시퀀스 끝 감지 (End-of-Sequence Detection)**: 모델이 자연스럽게 응답을 마치도록 합니다.

예를 들어, 단일 단락을 생성하려면 최대 100개의 토큰을 설정하고 "\n\n"을 중지 시퀀스로 사용할 수 있습니다. 이렇게 하면 출력이 목적에 맞게 집중되고 적절한 크기를 유지합니다.

![image](https://huggingface.co/reasoning-course/images/resolve/main/inference/3.png)  

### 빔 탐색: 더 나은 일관성을 위해 미리 보기 (Beam Search: Looking Ahead for Better Coherence)

지금까지 논의한 전략들이 한 번에 하나의 토큰을 결정하는 반면, **빔 탐색(beam search)**은 보다 전체적인 접근 방식을 취합니다. 각 단계에서 하나의 선택에 전념하는 대신, 여러 가능한 경로를 동시에 탐색합니다. 마치 체스 선수가 여러 수 앞을 생각하는 것과 같습니다.

![image](https://huggingface.co/reasoning-course/images/resolve/main/inference/4.png)  

작동 방식은 다음과 같습니다:
1. 각 단계에서 여러 후보 시퀀스(일반적으로 5~10개)를 유지합니다.
2. 각 후보에 대해 다음 토큰의 확률을 계산합니다.
3. 시퀀스와 다음 토큰의 가장 유망한 조합만 유지합니다.
4. 원하는 길이 또는 중지 조건에 도달할 때까지 이 프로세스를 계속합니다.
5. 전체 확률이 가장 높은 시퀀스를 선택합니다.

여기에서 빔 탐색을 시각적으로 탐색할 수 있습니다:

<iframe
	src="https://agents-course-beam-search-visualizer.hf.space"
	frameborder="0"
	width="850"
	height="450"
></iframe>

이 접근 방식은 더 간단한 방법보다 더 많은 계산 자원을 필요로 하지만, 종종 더 일관성 있고 문법적으로 정확한 텍스트를 생성합니다.

## 실제적인 도전과 최적화 (Practical Challenges and Optimization)

LLM 추론에 대한 탐구를 마무리하면서, 이러한 모델을 배포할 때 직면하게 될 실제적인 도전과 성능을 측정하고 최적화하는 방법을 살펴보겠습니다.

### 핵심 성능 지표 (Key Performance Metrics)

LLM을 다룰 때, 네 가지 중요한 지표가 구현 결정을 좌우할 것입니다:

1. **첫 토큰까지 걸리는 시간 (Time to First Token, TTFT)**: 첫 번째 응답을 얼마나 빨리 얻을 수 있습니까? 이는 사용자 경험에 매우 중요하며 주로 **프리필 단계**의 영향을 받습니다.
2. **출력 토큰당 시간 (Time Per Output Token, TPOT)**: 후속 토큰을 얼마나 빨리 생성할 수 있습니까? 이는 전체 생성 속도를 결정합니다.
3. **처리량 (Throughput)**: 동시에 몇 개의 요청을 처리할 수 있습니까? 이는 확장 및 비용 효율성에 영향을 미칩니다.
4. **VRAM 사용량 (VRAM Usage)**: 얼마나 많은 GPU 메모리가 필요합니까? 이는 종종 실제 응용 분야에서 주요 제약이 됩니다.

### 문맥 길이의 도전 (The Context Length Challenge)

LLM 추론에서 가장 중요한 도전 과제 중 하나는 문맥 길이를 효과적으로 관리하는 것입니다. 더 긴 문맥은 더 많은 정보를 제공하지만, 상당한 비용이 따릅니다:

- **메모리 사용량 (Memory Usage)**: 문맥 길이에 따라 **제곱으로 증가**합니다.
- **처리 속도 (Processing Speed)**: 문맥이 길어질수록 **선형적으로 감소**합니다.
- **자원 할당 (Resource Allocation)**: VRAM 사용량의 신중한 균형 조정이 필요합니다.

[Qwen2.5-1M](https://huggingface.co/Qwen/Qwen2.5-14B-Instruct-1M)과 같은 최신 모델은 인상적인 1M 토큰 문맥 창을 제공하지만, 이는 현저히 느린 추론 시간이라는 대가를 치릅니다. 핵심은 특정 사용 사례에 적합한 균형을 찾는 것입니다.

<div style="max-width: 800px; margin: 20px auto; padding: 20px; 
font-family: system-ui;">
    <div style="border: 2px solid #ddd; border-radius: 8px; 
    padding: 20px; margin-bottom: 20px;">
        <div style="display: flex; align-items: center; 
        margin-bottom: 15px;">
            <div style="flex: 1; text-align: center; padding: 
            10px; background: #f0f0f0; border-radius: 4px;">
                입력 텍스트 (원본)
            </div>
            <div style="margin: 0 10px;">→</div>
            <div style="flex: 1; text-align: center; padding: 
            10px; background: #e1f5fe; border-radius: 4px;">
                토큰화된 입력
            </div>
        </div>
        <div style="display: flex; margin-bottom: 15px;">
            <div style="flex: 1; border: 1px solid #ccc; 
            padding: 10px; margin: 5px; background: #e8f5e9; 
            border-radius: 4px; text-align: center;">
                문맥 창<br/>(예: 4K 토큰)
                <div style="display: flex; margin-top: 10px;">
                    <div style="flex: 1; background: #81c784; 
                    margin: 2px; height: 20px; border-radius: 
                    2px;"></div>
                    <div style="flex: 1; background: #81c784; 
                    margin: 2px; height: 20px; border-radius: 
                    2px;"></div>
                    <div style="flex: 1; background: #81c784; 
                    margin: 2px; height: 20px; border-radius: 
                    2px;"></div>
                    <div style="flex: 1; background: #81c784; 
                    margin: 2px; height: 20px; border-radius: 
                    2px;"></div>
                </div>
            </div>
        </div>
        <div style="display: flex; justify-content: 
        space-between; text-align: center; font-size: 0.9em; 
        color: #666;">
            <div style="flex: 1;">
                <div style="border: 1px solid #ffcc80; padding: 
                8px; margin: 5px; background: #fff3e0; 
                border-radius: 4px;">
                    메모리 사용량<br/>∝ 길이²
                </div>
            </div>
            <div style="flex: 1;">
                <div style="border: 1px solid #90caf9; padding: 
                8px; margin: 5px; background: #e3f2fd; 
                border-radius: 4px;">
                    처리 시간<br/>∝ 길이
                </div>
            </div>
        </div>
    </div>
</div>

### KV 캐시 최적화 (The KV Cache Optimization)

이러한 문제들을 해결하기 위해 가장 강력한 최적화 기술 중 하나는 **KV (Key-Value) 캐싱**입니다. 이 기술은 중간 계산을 저장하고 재사용함으로써 추론 속도를 크게 향상시킵니다. 이 최적화는 다음과 같습니다:
- 반복적인 계산을 줄입니다.
- 생성 속도를 향상시킵니다.
- 긴 문맥 생성을 실용적으로 만듭니다.

이로 인한 단점은 추가적인 메모리 사용이지만, 성능 이점이 일반적으로 이 비용보다 훨씬 큽니다.

## 결론 (Conclusion)

LLM 추론을 이해하는 것은 이러한 강력한 모델을 효과적으로 배포하고 최적화하는 데 중요합니다. 우리는 다음과 같은 핵심 구성 요소를 다루었습니다:

- 어텐션과 문맥의 근본적인 역할
- 2단계 추론 프로세스
- 생성을 제어하기 위한 다양한 샘플링 전략
- 실제적인 도전과 최적화

이러한 개념을 숙달하면 LLM을 효과적이고 효율적으로 활용하는 응용 프로그램을 구축할 수 있는 더 나은 준비를 갖추게 될 것입니다.

LLM 추론 분야는 새로운 기술과 최적화가 정기적으로 등장하면서 빠르게 발전하고 있음을 기억하십시오. 호기심을 유지하고 특정 사용 사례에 가장 적합한 것을 찾기 위해 다양한 접근 방식을 계속 실험하십시오.
