### [단원 마무리 퀴즈](https://huggingface.co/learn/llm-course/ko/chapter1/10)

이번 챕터에서는 정말 많은 내용들을 다뤘습니다! 그러니 모든 세부 사항을 다 이해하지 못했다고 해서 좌절하지 마세요. 다음 챕터에서 다루는 내용은 내부 작동 방식을 이해하는 데에 도움이 될거에요.
그래도 우선, 이번 챕터에서 배운 내용에 대해 확인해보는 시간을 갖도록 하겠습니다!

1. **Hub에서 roberta-large-mnli 체크포인트를 검색해 보세요. 이 모델은 어떤 작업을 수행하나요?**
    1. 요약
    2. 텍스트 분류
    3. 텍스트 생성

2. **다음 코드는 무엇을 반환하나요?**
    ```python
    from transformers import pipeline
    
    ner = pipeline("ner", grouped_entities=True)
    ner("My name is Sylvain and I work at Hugging Face in Brooklyn.")
    ```
    1. 문장에 대해 "positive" 혹은 "negative" 로 분류한 레이블과 함께 분류 점수를 반환합니다.
    2. 이 문장을 완성할, 생성 텍스트를 반환합니다.
    3. 사람, 기관, 장소 등을 나타내는 단어들을 반환합니다.

3. **다음 예제 코드에서 … 대신 무엇이 들어가야 할까요?**

    ```python
    from transformers import pipeline
    
    filler = pipeline("fill-mask", model="bert-base-cased")
    result = filler("...")
    ```

    1. [MASK]
    2. man

4. **다음 코드가 실행되지 않는 이유는 무엇일까요?**

    ```python
    from transformers import pipeline
    
    classifier = pipeline("zero-shot-classification")
    result = classifier("This is a course about the Transformers library")
    ```
    1. 해당 텍스트를 분류하기 위해서는 파이프라인에 레이블을 넣어주어야 합니다.
    2. 한 문장이 아니라, 여러 문장을 파이프라인에 넣어주어야 합니다.
    3. 늘 그렇듯 🤗 Transformers 라이브러리가 또 고장난거 아닌가요?
    4. 위의 문장은 너무 짧아서, 더 긴 문장을 입력해야 합니다.

5. **“전이 학습(transfer learning)“이란 무엇을 의미하나요?**
    1. 동일한 데이터셋으로 학습할 때, 사전 학습된 모델의 지식이 새로운 모델로 전달되는 것
    2. 사전 학습된 모델의 가중치로 새로운 모델을 초기화할 때, 사전 학습된 모델의 지식이 전달되는 것
    3. 사전 학습된 모델과 동일한 구조의 모델을 새로 만들 때, 사전 학습 모델의 지식이 전달되는 것

6. **언어 모델은 일반적으로 사전 학습시에 레이블을 필요로 하지 않습니다. 이 문장은 참일까요 거짓일까요?**
    1. 참
    2. 거짓

7. **다음 중 “모델(model)”, “구조(architecture)”, “가중치(weights)”에 대해 가장 잘 설명한 것을 고르세요.**
    1. 모델이 하나의 빌딩이라면, 구조는 청사진이고 가중치는 그 안에 사는 사람들입니다.
    2. 구조는 모델 구축을 위한 일종의 지도이고 가중치는 그 지도에 나타난 도시들에 해당합니다.
    3. 구조는 모델을 구축하기 위한 수학적 함수의 연속이고 가중치는 그 함수들의 변수(parameters)입니다.

8. **다음 중 어떤 모델이 텍스트를 생성하여 프롬프트(prompt)를 완성시키는 데에 가장 적합할까요?**
    1. 인코더 모델
    2. 디코더 모델
    3. 시퀀스-투-시퀀스 모델

9. **다음 중 어떤 모델이 텍스트 요약에 가장 적합할까요?**
    1. 인코더 모델
    2. 디코더 모델
    3. 시퀀스-투-시퀀스 모델

10. **다음 중 어떤 모델이 입력 텍스트를 특정 레이블로 분류하는 데에 가장 적합할까요?**
    1. 인코더 모델
    2. 디코더 모델
    3. 시퀀스-투-시퀀스 모델

11. **다음 중 모델이 편향성(bias)을 갖게 되는 데에 가장 가능성 있는 원인을 모두 고르세요.**
    1. 모델은 사전 학습 모델의 미세 조정된 버전이고, 여기서 편향성이 따라오게 됩니다.
    2. 모델 학습에 사용된 데이터가 편향되어 있습니다.
    3. 모델이 최적화한 메트릭(metric)이 편향되어 있습니다.


---
### 단원 마무리 퀴즈 정답

1. **Hub에서 roberta-large-mnli 체크포인트를 검색해 보세요. 이 모델은 어떤 작업을 수행하나요?**
    * 정답: **2. 텍스트 분류**
    * (설명: **MNLI**는 'Multi-Genre Natural Language Inference'를 의미하는 분류 작업입니다.)

2. **다음 코드는 무엇을 반환하나요?**
    * 정답: **3. 사람, 기관, 장소 등을 나타내는 단어들을 반환합니다.**
    * (설명: `pipeline("ner", ...)`는 **개체명 인식(Named Entity Recognition)** 파이프라인입니다.)

3. **다음 예제 코드에서 … 대신 무엇이 들어가야 할까요?**
    * 정답: **1. [MASK]**
    * (설명: **BERT**와 같은 **Masked Language Model**은 빈칸을 채우기 위해 **[MASK]** 토큰을 사용합니다.)

4. **다음 코드가 실행되지 않는 이유는 무엇일까요?**
    * 정답: **1. 해당 텍스트를 분류하기 위해서는 파이프라인에 레이블을 넣어주어야 합니다.**
    * (설명: `zero-shot-classification`은 분류할 **후보 레이블(candidate labels)** 목록이 필수입니다.)

5. **“전이 학습(transfer learning)“이란 무엇을 의미하나요?**
    * 정답: **2. 사전 학습된 모델의 가중치로 새로운 모델을 초기화할 때, 사전 학습된 모델의 지식이 전달되는 것**
    * (설명: 전이 학습은 이미 학습된 모델의 **가중치(지식)**를 새로운 작업에 전이하여 사용하는 것을 말합니다.)

6. **언어 모델은 일반적으로 사전 학습시에 레이블을 필요로 하지 않습니다. 이 문장은 참일까요 거짓일까요?**
    * 정답: **1. 참**
    * (설명: 언어 모델은 **레이블이 없는** 대규모 텍스트 데이터로 사전 학습될 수 있습니다.)

7. **다음 중 “모델(model)”, “구조(architecture)”, “가중치(weights)”에 대해 가장 잘 설명한 것을 고르세요.**
    * 정답: **3. 구조는 모델을 구축하기 위한 수학적 함수의 연속이고 가중치는 그 함수들의 변수(parameters)입니다.**
    * (설명: **구조**는 함수의 배열이며, **가중치**는 학습을 통해 조정되는 함수의 매개변수입니다.)

8. **다음 중 어떤 모델이 텍스트를 생성하여 프롬프트(prompt)를 완성시키는 데에 가장 적합할까요?**
    * 정답: **2. 디코더 모델**
    * (설명: **디코더 모델**은 텍스트를 순차적으로 생성(오토회귀적 생성)하도록 설계되었습니다.)

9. **다음 중 어떤 모델이 텍스트 요약에 가장 적합할까요?**
    * 정답: **3. 시퀀스-투-시퀀스 모델**
    * (설명: **시퀀스-투-시퀀스 모델**은 긴 입력 시퀀스를 짧은 출력 시퀀스로 변환하는 데 사용됩니다.)

10. **다음 중 어떤 모델이 입력 텍스트를 특정 레이블로 분류하는 데에 가장 적합할까요?**
    * 정답: **1. 인코더 모델**
    * (설명: **인코더 모델**은 텍스트를 이해하고 분류하는 데 필요한 표현을 생성하는 데 적합합니다.)

11. **다음 중 모델이 편향성(bias)을 갖게 되는 데에 가장 가능성 있는 원인을 모두 고르세요.**
    * 정답: **1, 2, 3 모두**
    * (설명: 편향성은 **사전 학습된 모델**(1), **훈련 데이터**(2), 모델 성능을 측정하는 **메트릭**(3) 모두에서 비롯될 수 있습니다.)
